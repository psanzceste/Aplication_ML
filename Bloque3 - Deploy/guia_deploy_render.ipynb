{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a0062e",
   "metadata": {},
   "source": [
    "# Gu√≠a de Despliegue de Modelos ML en Render\n",
    "\n",
    "Este notebook proporciona una gu√≠a completa para desplegar modelos de Machine Learning en **Render** utilizando dos enfoques:\n",
    "\n",
    "1. **Despliegue sin Docker** (Nativo)\n",
    "2. **Despliegue con Docker** (Containerizado)\n",
    "\n",
    "---\n",
    "\n",
    "## ¬øQu√© es Render?\n",
    "\n",
    "Render es una plataforma de cloud computing moderna que permite desplegar aplicaciones web, APIs, bases de datos y m√°s de forma sencilla. Es una alternativa a Heroku con un plan gratuito m√°s generoso.\n",
    "\n",
    "**Caracter√≠sticas principales:**\n",
    "- ‚úÖ Plan gratuito disponible\n",
    "- ‚úÖ Integraci√≥n con GitHub/GitLab\n",
    "- ‚úÖ Despliegue autom√°tico (CI/CD)\n",
    "- ‚úÖ Soporte para Docker\n",
    "- ‚úÖ SSL gratuito\n",
    "- ‚úÖ Variables de entorno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc395134",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Requisitos Previos\n",
    "\n",
    "1. **Cuenta en Render**: Crear una cuenta gratuita en [render.com](https://render.com)\n",
    "2. **Repositorio Git**: Tu c√≥digo debe estar en GitHub o GitLab\n",
    "3. **Aplicaci√≥n Flask/FastAPI**: Una API funcional para tu modelo\n",
    "4. **Modelo entrenado**: Tu modelo ML guardado (pickle, joblib, h5, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4798e5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PARTE 1: Despliegue SIN Docker\n",
    "\n",
    "## üìã Estructura del Proyecto\n",
    "\n",
    "```\n",
    "mi-proyecto-ml/\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ app.py                  # Aplicaci√≥n Flask/FastAPI\n",
    "‚îú‚îÄ‚îÄ requirements.txt        # Dependencias de Python\n",
    "‚îú‚îÄ‚îÄ model.pkl              # Modelo entrenado\n",
    "‚îú‚îÄ‚îÄ scaler.pkl             # Preprocesadores (opcional)\n",
    "‚îî‚îÄ‚îÄ README.md              # Documentaci√≥n\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8eb863",
   "metadata": {},
   "source": [
    "## 1.1 Crear la Aplicaci√≥n Flask\n",
    "\n",
    "Ejemplo de una API sencilla con Flask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd50985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py - Ejemplo de API con Flask\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Cargar el modelo\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Opcional: Cargar scaler u otros preprocesadores\n",
    "# with open('scaler.pkl', 'rb') as f:\n",
    "#     scaler = pickle.load(f)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return jsonify({\n",
    "        'message': 'API de Machine Learning',\n",
    "        'version': '1.0',\n",
    "        'endpoints': ['/predict']\n",
    "    })\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        # Obtener datos del request\n",
    "        data = request.get_json()\n",
    "        features = np.array(data['features']).reshape(1, -1)\n",
    "        \n",
    "        # Realizar predicci√≥n\n",
    "        prediction = model.predict(features)\n",
    "        \n",
    "        return jsonify({\n",
    "            'prediction': prediction.tolist(),\n",
    "            'status': 'success'\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'error': str(e),\n",
    "            'status': 'error'\n",
    "        }), 400\n",
    "\n",
    "@app.route('/health')\n",
    "def health():\n",
    "    return jsonify({'status': 'healthy'})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Render asigna el puerto din√°micamente\n",
    "    port = int(os.environ.get('PORT', 5000))\n",
    "    app.run(host='0.0.0.0', port=port)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6083078e",
   "metadata": {},
   "source": [
    "## 1.2 Crear requirements.txt\n",
    "\n",
    "Es **crucial** especificar todas las dependencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43735ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txt\n",
    "\n",
    "# Web Framework\n",
    "flask==2.3.3\n",
    "gunicorn==21.2.0\n",
    "\n",
    "# Machine Learning\n",
    "scikit-learn==1.3.0\n",
    "numpy==1.24.3\n",
    "pandas==2.0.3\n",
    "\n",
    "# Opcional: seg√∫n tu modelo\n",
    "# tensorflow==2.13.0\n",
    "# torch==2.0.1\n",
    "# xgboost==1.7.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0077c4",
   "metadata": {},
   "source": [
    "## 1.3 Configurar Render (Sin Docker)\n",
    "\n",
    "### Pasos en la interfaz de Render:\n",
    "\n",
    "1. **Crear un nuevo Web Service**\n",
    "   - Dashboard ‚Üí New ‚Üí Web Service\n",
    "   - Conectar tu repositorio de GitHub/GitLab\n",
    "\n",
    "2. **Configuraci√≥n del servicio:**\n",
    "   ```\n",
    "   Name: mi-api-ml\n",
    "   Environment: Python 3\n",
    "   Region: Oregon (o el m√°s cercano)\n",
    "   Branch: main\n",
    "   Build Command: pip install -r requirements.txt\n",
    "   Start Command: gunicorn app:app\n",
    "   ```\n",
    "\n",
    "3. **Plan:**\n",
    "   - Free (para pruebas)\n",
    "   - Starter ($7/mes) o superior (para producci√≥n)\n",
    "\n",
    "4. **Variables de entorno** (opcional):\n",
    "   - A√±adir API keys, configuraciones, etc.\n",
    "\n",
    "5. **Click en \"Create Web Service\"**\n",
    "\n",
    "### ‚ö†Ô∏è Limitaciones del Plan Gratuito:\n",
    "- El servicio se apaga despu√©s de 15 minutos de inactividad\n",
    "- Primera petici√≥n puede tardar ~30 segundos (cold start)\n",
    "- 750 horas/mes de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69771938",
   "metadata": {},
   "source": [
    "## 1.4 Archivo de Configuraci√≥n render.yaml (Opcional)\n",
    "\n",
    "Puedes crear un archivo `render.yaml` en la ra√≠z de tu proyecto para automatizar la configuraci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b31329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render.yaml\n",
    "\n",
    "services:\n",
    "  - type: web\n",
    "    name: mi-api-ml\n",
    "    env: python\n",
    "    buildCommand: pip install -r requirements.txt\n",
    "    startCommand: gunicorn app:app\n",
    "    envVars:\n",
    "      - key: PYTHON_VERSION\n",
    "        value: 3.11.0\n",
    "      - key: MODEL_PATH\n",
    "        value: ./model.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db68fb14",
   "metadata": {},
   "source": [
    "## 1.5 Probar el Despliegue\n",
    "\n",
    "Una vez desplegado, Render te dar√° una URL como: `https://mi-api-ml.onrender.com`\n",
    "\n",
    "Pru√©bala con Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# URL de tu API en Render\n",
    "url = 'https://mi-api-ml.onrender.com/predict'\n",
    "\n",
    "# Datos de ejemplo\n",
    "data = {\n",
    "    'features': [5.1, 3.5, 1.4, 0.2]  # Ejemplo: Iris dataset\n",
    "}\n",
    "\n",
    "# Hacer la petici√≥n\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "# Mostrar resultado\n",
    "print('Status Code:', response.status_code)\n",
    "print('Response:', json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31960450",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PARTE 2: Despliegue CON Docker\n",
    "\n",
    "## üìã Estructura del Proyecto con Docker\n",
    "\n",
    "```\n",
    "mi-proyecto-ml/\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ app.py                  # Aplicaci√≥n Flask/FastAPI\n",
    "‚îú‚îÄ‚îÄ requirements.txt        # Dependencias de Python\n",
    "‚îú‚îÄ‚îÄ Dockerfile             # Instrucciones para crear la imagen\n",
    "‚îú‚îÄ‚îÄ .dockerignore          # Archivos a ignorar en la imagen\n",
    "‚îú‚îÄ‚îÄ model.pkl              # Modelo entrenado\n",
    "‚îî‚îÄ‚îÄ README.md              # Documentaci√≥n\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d291b",
   "metadata": {},
   "source": [
    "## 2.1 Crear el Dockerfile\n",
    "\n",
    "El Dockerfile es la receta para construir tu contenedor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e735d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dockerfile\n",
    "\n",
    "# Imagen base de Python\n",
    "FROM python:3.11-slim\n",
    "\n",
    "# Establecer directorio de trabajo\n",
    "WORKDIR /app\n",
    "\n",
    "# Copiar archivos de dependencias\n",
    "COPY requirements.txt .\n",
    "\n",
    "# Instalar dependencias\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copiar el c√≥digo de la aplicaci√≥n\n",
    "COPY . .\n",
    "\n",
    "# Exponer el puerto (Render usa la variable PORT)\n",
    "EXPOSE 5000\n",
    "\n",
    "# Comando para ejecutar la aplicaci√≥n\n",
    "CMD [\"gunicorn\", \"--bind\", \"0.0.0.0:5000\", \"app:app\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3493e6b7",
   "metadata": {},
   "source": [
    "## 2.2 Crear .dockerignore\n",
    "\n",
    "Para evitar copiar archivos innecesarios a la imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fba139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .dockerignore\n",
    "\n",
    "# Python\n",
    "__pycache__\n",
    "*.pyc\n",
    "*.pyo\n",
    "*.pyd\n",
    ".Python\n",
    "env/\n",
    "venv/\n",
    ".venv\n",
    "\n",
    "# IDE\n",
    ".vscode/\n",
    ".idea/\n",
    "*.swp\n",
    "*.swo\n",
    "\n",
    "# Git\n",
    ".git\n",
    ".gitignore\n",
    "\n",
    "# Documentaci√≥n\n",
    "README.md\n",
    "*.md\n",
    "\n",
    "# Jupyter\n",
    "*.ipynb\n",
    ".ipynb_checkpoints\n",
    "\n",
    "# Datos de entrenamiento (si son grandes)\n",
    "data/\n",
    "*.csv\n",
    "\n",
    "# Tests\n",
    "tests/\n",
    "test_*.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d162f5e",
   "metadata": {},
   "source": [
    "## 2.3 Probar Docker Localmente\n",
    "\n",
    "Antes de desplegar, prueba el contenedor en tu m√°quina:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ce821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En la terminal:\n",
    "\n",
    "# 1. Construir la imagen\n",
    "# docker build -t mi-api-ml:latest .\n",
    "\n",
    "# 2. Ejecutar el contenedor\n",
    "# docker run -p 5000:5000 mi-api-ml:latest\n",
    "\n",
    "# 3. Probar en otra terminal\n",
    "# curl http://localhost:5000\n",
    "\n",
    "# 4. Ver logs\n",
    "# docker logs <container_id>\n",
    "\n",
    "# 5. Detener el contenedor\n",
    "# docker stop <container_id>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c153171",
   "metadata": {},
   "source": [
    "## 2.4 Configurar Render (Con Docker)\n",
    "\n",
    "### Opci√≥n A: Desde el Dashboard de Render\n",
    "\n",
    "1. **Crear un nuevo Web Service**\n",
    "   - Dashboard ‚Üí New ‚Üí Web Service\n",
    "   - Conectar repositorio\n",
    "\n",
    "2. **Configuraci√≥n:**\n",
    "   ```\n",
    "   Name: mi-api-ml-docker\n",
    "   Environment: Docker\n",
    "   Region: Oregon\n",
    "   Branch: main\n",
    "   Dockerfile Path: ./Dockerfile (o ./Dockerfile si est√° en la ra√≠z)\n",
    "   ```\n",
    "\n",
    "3. **No necesitas especificar Build/Start Command** (usa el Dockerfile)\n",
    "\n",
    "4. **Click en \"Create Web Service\"**\n",
    "\n",
    "### Opci√≥n B: Con render.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e0509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render.yaml (para Docker)\n",
    "\n",
    "services:\n",
    "  - type: web\n",
    "    name: mi-api-ml-docker\n",
    "    env: docker\n",
    "    dockerfilePath: ./Dockerfile\n",
    "    plan: free\n",
    "    healthCheckPath: /health\n",
    "    envVars:\n",
    "      - key: MODEL_VERSION\n",
    "        value: v1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94505ac9",
   "metadata": {},
   "source": [
    "## 2.5 Manejo del Puerto en Docker\n",
    "\n",
    "‚ö†Ô∏è **Importante**: Render asigna el puerto din√°micamente mediante la variable `PORT`.\n",
    "\n",
    "Aseg√∫rate de que tu aplicaci√≥n use esta variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dec2bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En app.py\n",
    "import os\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    port = int(os.environ.get('PORT', 5000))\n",
    "    app.run(host='0.0.0.0', port=port)\n",
    "\n",
    "# O en el CMD del Dockerfile con gunicorn:\n",
    "# CMD gunicorn --bind 0.0.0.0:$PORT app:app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a142e832",
   "metadata": {},
   "source": [
    "### Dockerfile con variable PORT din√°mica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d616aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dockerfile con PORT din√°mico\n",
    "\n",
    "FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "\n",
    "# No especificar EXPOSE ya que el puerto es din√°mico\n",
    "\n",
    "# Usar una variable de entorno para el puerto\n",
    "ENV PORT=5000\n",
    "\n",
    "# Ejecutar con el puerto din√°mico\n",
    "CMD gunicorn --bind 0.0.0.0:$PORT --workers 2 app:app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151a0991",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Comparaci√≥n: Docker vs Sin Docker\n",
    "\n",
    "| Caracter√≠stica | Sin Docker | Con Docker |\n",
    "|---------------|------------|------------|\n",
    "| **Simplicidad** | ‚úÖ M√°s simple | ‚ö†Ô∏è Requiere conocer Docker |\n",
    "| **Velocidad de build** | ‚úÖ R√°pido | ‚ö†Ô∏è M√°s lento |\n",
    "| **Reproducibilidad** | ‚ö†Ô∏è Depende del entorno | ‚úÖ Totalmente reproducible |\n",
    "| **Portabilidad** | ‚ö†Ô∏è Limitada | ‚úÖ Funciona en cualquier lado |\n",
    "| **Control del entorno** | ‚ö†Ô∏è Limitado | ‚úÖ Control total |\n",
    "| **Tama√±o** | ‚úÖ Ligero | ‚ö†Ô∏è Imagen m√°s pesada |\n",
    "| **Dependencias del sistema** | ‚ö†Ô∏è Limitadas | ‚úÖ Instalar lo que necesites |\n",
    "| **Debugging** | ‚úÖ M√°s f√°cil | ‚ö†Ô∏è M√°s complejo |\n",
    "\n",
    "## ¬øCu√°ndo usar cada opci√≥n?\n",
    "\n",
    "### Sin Docker:\n",
    "- ‚úÖ Proyectos simples con pocas dependencias\n",
    "- ‚úÖ Prototipado r√°pido\n",
    "- ‚úÖ Solo Python y librer√≠as est√°ndar\n",
    "- ‚úÖ Equipo sin experiencia en Docker\n",
    "\n",
    "### Con Docker:\n",
    "- ‚úÖ Dependencias complejas (ej: librer√≠as del sistema)\n",
    "- ‚úÖ Necesitas exactamente la misma versi√≥n de Python\n",
    "- ‚úÖ M√∫ltiples servicios (API + DB + Redis, etc.)\n",
    "- ‚úÖ Proyecto que se desplegar√° en m√∫ltiples plataformas\n",
    "- ‚úÖ Producci√≥n con alta confiabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef916f8f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Mejores Pr√°cticas\n",
    "\n",
    "## 1. Salud y Monitoreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156758cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A√±adir endpoints de salud y m√©tricas\n",
    "\n",
    "@app.route('/health')\n",
    "def health():\n",
    "    return jsonify({\n",
    "        'status': 'healthy',\n",
    "        'model_loaded': model is not None,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    })\n",
    "\n",
    "@app.route('/info')\n",
    "def info():\n",
    "    return jsonify({\n",
    "        'version': '1.0.0',\n",
    "        'model_type': 'RandomForest',\n",
    "        'features': ['feature1', 'feature2', 'feature3'],\n",
    "        'last_updated': '2024-01-15'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f4a59d",
   "metadata": {},
   "source": [
    "## 2. Gesti√≥n de Errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e651d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manejo robusto de errores\n",
    "\n",
    "from functools import wraps\n",
    "import logging\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def handle_errors(f):\n",
    "    @wraps(f)\n",
    "    def decorated_function(*args, **kwargs):\n",
    "        try:\n",
    "            return f(*args, **kwargs)\n",
    "        except ValueError as e:\n",
    "            logger.error(f'ValueError: {str(e)}')\n",
    "            return jsonify({'error': 'Invalid input', 'details': str(e)}), 400\n",
    "        except Exception as e:\n",
    "            logger.error(f'Unexpected error: {str(e)}')\n",
    "            return jsonify({'error': 'Internal server error'}), 500\n",
    "    return decorated_function\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "@handle_errors\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "    # ... l√≥gica de predicci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a7c15b",
   "metadata": {},
   "source": [
    "## 3. Validaci√≥n de Entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a744888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validar datos de entrada\n",
    "\n",
    "from pydantic import BaseModel, validator\n",
    "from typing import List\n",
    "\n",
    "class PredictionRequest(BaseModel):\n",
    "    features: List[float]\n",
    "    \n",
    "    @validator('features')\n",
    "    def validate_features(cls, v):\n",
    "        if len(v) != 4:  # Ejemplo: esperas 4 features\n",
    "            raise ValueError('Se requieren exactamente 4 caracter√≠sticas')\n",
    "        if any(x < 0 for x in v):\n",
    "            raise ValueError('Las caracter√≠sticas no pueden ser negativas')\n",
    "        return v\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        data = PredictionRequest(**request.get_json())\n",
    "        # Continuar con la predicci√≥n...\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc63671",
   "metadata": {},
   "source": [
    "## 4. Variables de Entorno\n",
    "\n",
    "Nunca pongas credenciales en el c√≥digo. Usa variables de entorno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85132665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar variables de entorno\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Para desarrollo local\n",
    "load_dotenv()\n",
    "\n",
    "# Obtener configuraciones\n",
    "MODEL_PATH = os.getenv('MODEL_PATH', 'model.pkl')\n",
    "API_KEY = os.getenv('API_KEY', '')\n",
    "DEBUG = os.getenv('DEBUG', 'False') == 'True'\n",
    "\n",
    "# En Render, a√±√°delas en: Settings ‚Üí Environment Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3833c0d4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Soluci√≥n de Problemas Comunes\n",
    "\n",
    "## 1. El servicio no arranca\n",
    "\n",
    "**S√≠ntomas**: Build exitoso pero no responde\n",
    "\n",
    "**Soluciones**:\n",
    "- ‚úÖ Verificar que usas `0.0.0.0` como host\n",
    "- ‚úÖ Usar la variable `PORT` de entorno\n",
    "- ‚úÖ Revisar los logs en Render (dashboard)\n",
    "- ‚úÖ A√±adir endpoint `/health` y configurarlo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00546ac4",
   "metadata": {},
   "source": [
    "## 2. Error de memoria\n",
    "\n",
    "**S√≠ntomas**: `MemoryError` o el servicio se reinicia\n",
    "\n",
    "**Soluciones**:\n",
    "- ‚úÖ Plan gratuito tiene 512MB RAM\n",
    "- ‚úÖ Reducir workers de Gunicorn: `--workers 1`\n",
    "- ‚úÖ Usar modelos m√°s ligeros\n",
    "- ‚úÖ Cargar el modelo una sola vez (no en cada request)\n",
    "- ‚úÖ Actualizar a plan de pago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0933534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo eficientemente\n",
    "\n",
    "# ‚ùå MAL - Carga en cada request\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    model = pickle.load(open('model.pkl', 'rb'))  # ¬°NO!\n",
    "    # ...\n",
    "\n",
    "# ‚úÖ BIEN - Carga una sola vez al inicio\n",
    "model = pickle.load(open('model.pkl', 'rb'))\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Usar el modelo ya cargado\n",
    "    prediction = model.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bc78f5",
   "metadata": {},
   "source": [
    "## 3. Build muy lento\n",
    "\n",
    "**Soluciones**:\n",
    "- ‚úÖ Usar imagen base slim: `python:3.11-slim`\n",
    "- ‚úÖ Aprovechar cache de Docker (COPY requirements antes que el c√≥digo)\n",
    "- ‚úÖ Usar `.dockerignore` correctamente\n",
    "- ‚úÖ No instalar paquetes innecesarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de57b4b",
   "metadata": {},
   "source": [
    "## 4. Cold starts lentos\n",
    "\n",
    "**S√≠ntomas**: Primera petici√≥n tarda mucho\n",
    "\n",
    "**Soluciones**:\n",
    "- ‚úÖ Plan gratuito se apaga tras 15 min de inactividad\n",
    "- ‚úÖ Usar plan de pago (no se apaga)\n",
    "- ‚úÖ Implementar un \"ping\" peri√≥dico (cron job)\n",
    "- ‚úÖ Mostrar mensaje de carga al usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bcd5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script para mantener el servicio activo (usar con cron-job.org)\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def ping_service(url):\n",
    "    try:\n",
    "        response = requests.get(f'{url}/health', timeout=30)\n",
    "        print(f'[{datetime.now()}] Ping exitoso: {response.status_code}')\n",
    "    except Exception as e:\n",
    "        print(f'[{datetime.now()}] Error en ping: {str(e)}')\n",
    "\n",
    "# Ejecutar cada 10 minutos\n",
    "if __name__ == '__main__':\n",
    "    url = 'https://mi-api-ml.onrender.com'\n",
    "    while True:\n",
    "        ping_service(url)\n",
    "        time.sleep(600)  # 10 minutos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8182f8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Ejemplo Completo: API de Iris Classification\n",
    "\n",
    "Aqu√≠ un ejemplo completo listo para desplegar:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd383dd",
   "metadata": {},
   "source": [
    "## Paso 1: Entrenar y guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe000dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model.py\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# Cargar datos\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Dividir datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar modelo\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy:.2%}')\n",
    "\n",
    "# Guardar modelo\n",
    "with open('iris_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print('Modelo guardado como iris_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8125d026",
   "metadata": {},
   "source": [
    "## Paso 2: Crear la API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b43f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Cargar modelo al inicio\n",
    "with open('iris_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "IRIS_SPECIES = ['setosa', 'versicolor', 'virginica']\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return jsonify({\n",
    "        'message': 'Iris Classification API',\n",
    "        'version': '1.0',\n",
    "        'endpoints': {\n",
    "            '/': 'Info de la API',\n",
    "            '/predict': 'POST - Clasificar iris',\n",
    "            '/health': 'Health check'\n",
    "        },\n",
    "        'example': {\n",
    "            'url': '/predict',\n",
    "            'method': 'POST',\n",
    "            'body': {\n",
    "                'sepal_length': 5.1,\n",
    "                'sepal_width': 3.5,\n",
    "                'petal_length': 1.4,\n",
    "                'petal_width': 0.2\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        \n",
    "        # Extraer features\n",
    "        features = np.array([\n",
    "            data['sepal_length'],\n",
    "            data['sepal_width'],\n",
    "            data['petal_length'],\n",
    "            data['petal_width']\n",
    "        ]).reshape(1, -1)\n",
    "        \n",
    "        # Predicci√≥n\n",
    "        prediction = model.predict(features)[0]\n",
    "        probabilities = model.predict_proba(features)[0]\n",
    "        \n",
    "        return jsonify({\n",
    "            'prediction': IRIS_SPECIES[prediction],\n",
    "            'prediction_index': int(prediction),\n",
    "            'probabilities': {\n",
    "                species: float(prob)\n",
    "                for species, prob in zip(IRIS_SPECIES, probabilities)\n",
    "            },\n",
    "            'confidence': float(max(probabilities)),\n",
    "            'status': 'success'\n",
    "        })\n",
    "    \n",
    "    except KeyError as e:\n",
    "        return jsonify({\n",
    "            'error': f'Campo requerido faltante: {str(e)}',\n",
    "            'status': 'error'\n",
    "        }), 400\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'error': str(e),\n",
    "            'status': 'error'\n",
    "        }), 500\n",
    "\n",
    "@app.route('/health')\n",
    "def health():\n",
    "    return jsonify({'status': 'healthy'})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    port = int(os.environ.get('PORT', 5000))\n",
    "    app.run(host='0.0.0.0', port=port, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0e590f",
   "metadata": {},
   "source": [
    "## Paso 3: Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b95bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txt\n",
    "\n",
    "flask==2.3.3\n",
    "gunicorn==21.2.0\n",
    "scikit-learn==1.3.0\n",
    "numpy==1.24.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8123c0c",
   "metadata": {},
   "source": [
    "## Paso 4: Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c537b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dockerfile\n",
    "\n",
    "FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "\n",
    "ENV PORT=5000\n",
    "\n",
    "CMD gunicorn --bind 0.0.0.0:$PORT --workers 2 app:app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924e3787",
   "metadata": {},
   "source": [
    "## Paso 5: Probar la API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_api.py\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# URL local o de Render\n",
    "url = 'http://localhost:5000/predict'\n",
    "# url = 'https://tu-api.onrender.com/predict'\n",
    "\n",
    "# Datos de prueba\n",
    "test_data = {\n",
    "    'sepal_length': 5.1,\n",
    "    'sepal_width': 3.5,\n",
    "    'petal_length': 1.4,\n",
    "    'petal_width': 0.2\n",
    "}\n",
    "\n",
    "# Hacer petici√≥n\n",
    "response = requests.post(url, json=test_data)\n",
    "\n",
    "# Mostrar resultado\n",
    "print('Status Code:', response.status_code)\n",
    "print('Response:')\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5754085",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Recursos Adicionales\n",
    "\n",
    "## Documentaci√≥n Oficial\n",
    "- [Render Docs](https://render.com/docs)\n",
    "- [Flask Documentation](https://flask.palletsprojects.com/)\n",
    "- [Gunicorn](https://gunicorn.org/)\n",
    "- [Docker Documentation](https://docs.docker.com/)\n",
    "\n",
    "## Alternativas a Render\n",
    "- **Railway**: Similar a Render, muy f√°cil de usar\n",
    "- **Fly.io**: Excelente rendimiento, free tier generoso\n",
    "- **Google Cloud Run**: Serverless, pago por uso\n",
    "- **AWS Lambda + API Gateway**: Para despliegues serverless\n",
    "- **Azure App Service**: Para entornos empresariales\n",
    "\n",
    "## Tips Extra\n",
    "\n",
    "1. **Versiona tus modelos**: Usa nombres con versi√≥n (`model_v1.pkl`)\n",
    "2. **Implementa A/B testing**: Despliega m√∫ltiples versiones\n",
    "3. **Usa cach√©**: Para predicciones repetidas\n",
    "4. **A√±ade rate limiting**: Protege tu API de abuso\n",
    "5. **Implementa autenticaci√≥n**: API keys para producci√≥n\n",
    "6. **Monitoriza**: Usa herramientas como Sentry o DataDog\n",
    "7. **Documenta**: Usa Swagger/OpenAPI para tu API"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
